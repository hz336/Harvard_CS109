{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uaoVZSrv48aE"
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "## Homework 4 - Regularization \n",
    "\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KsLD_en48aI"
   },
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- **This homework must be completed individually.**\n",
    "\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list.\n",
    "\n",
    "\n",
    "Names of people you have worked with goes here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KsLD_en48aI"
   },
   "source": [
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "O1guCDAx48aK",
    "outputId": "0aa1afea-ee13-46c0-cdf0-150d57fd1ad8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kh0dA7W48ad"
   },
   "source": [
    "import these libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j02kGLE-48ah"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Applications\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "from pandas.core import datetools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuing Bike Sharing Usage Data\n",
    "\n",
    "In this homework, we will focus on regularization and cross validation. We will continue to build regression models for the [Capital Bikeshare program](https://www.capitalbikeshare.com) in Washington D.C.  See homework 3 for more information about the Capital Bikeshare data that we'll be using extensively. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 1 [20pts]  Data pre-processing </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YNsROjOHaAA2"
   },
   "source": [
    "**1.1** Read in the provided `bikes_student.csv` to a data frame named `bikes_main`. Split it into a training set `bikes_train` and a validation set `bikes_val`. Use `random_state=90`, a test set size of .2, and stratify on month. Remember to specify the data's index column as you read it in.\n",
    "\n",
    "**1.2** As with last homework, the response will be the `counts` column and we'll drop `counts`, `registered` and `casual` for being trivial predictors, drop `workingday` and `month` for being multicollinear with other columns, and `dteday` for being inappropriate for regression. Write code to do this.\n",
    "\n",
    "Encapsulate this process as a function with appropriate inputs and outputs, and **test** your code by producing `practice_y_train` and `practice_X_train`.\n",
    "\n",
    "**1.3** Write a function to standardize a provided subset of columns in your training/validation/test sets. Remember that while you will be scaling all of your data, you must learn the scaling parameters (mean and SD) from only the training set.\n",
    "\n",
    "Test your code by building a list of all non-binary columns in your `practice_X_train` and scaling only those columns. Call the result `practice_X_train_scaled`. Display the `.describe()` and verify that you have correctly scaled all columns, including the polynomial columns.\n",
    "\n",
    "**Hint: employ the provided list of binary columns and use `pd.columns.difference()`**\n",
    "\n",
    "`binary_columns = [ 'holiday', 'workingday','Feb', 'Mar', 'Apr',\n",
    "       'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec', 'spring',\n",
    "       'summer', 'fall', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat',\n",
    "       'Cloudy', 'Snow', 'Storm']`\n",
    "\n",
    "\n",
    "**1.4** Write a code to augment your a dataset with higher-order features for `temp`, `atemp`, `hum`,`windspeed`, and `hour`. You should include ONLY the pure powers of these columns. So with degree=2 you should produce `atemp^2` and `hum^2` but not `atemp*hum` or any other two-feature interactions. \n",
    "\n",
    "\n",
    "Encapsulate this process as a function with appropriate inputs and outputs, and test your code by producing `practice_X_train_poly`, a training dataset with quadratic and cubic features built from `practice_X_train_scaled`, and printing `practice_X_train_poly`'s column names and `.head()`.\n",
    "\n",
    "**1.5** Write code to add interaction terms to the model. Specifically, we want interactions between the continuous predictors (`temp`,`atemp`, `hum`,`windspeed`) and the month and weekday dummies (`Feb`, `Mar`...`Dec`, `Mon`, `Tue`, ... `Sat`). That means you SHOULD build `atemp*Feb` and `hum*Mon` and so on, but NOT `Feb*Mar` and NOT `Feb*Tue`. The interaction terms should always be a continuous feature times a month dummy or a continuous feature times a weekday dummy.\n",
    "\n",
    "\n",
    "Encapsulate this process as a function with appropriate inputs and outputs, and test your code by adding interaction terms to `practice_X_train_poly` and show its column names and `.head()`**\n",
    "\n",
    "**1.6** Combine all your code so far into a function that takes in `bikes_train`, `bikes_val`, the names of columns for polynomial, the target column, the columns to be dropped and produces computation-ready design matrices `X_train` and `X_val` and responses `y_train` and `y_val`. Your final function should build correct, scaled design matrices with the stated interaction terms and any polynomial degree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Read in the provided `bikes_student.csv` to a data frame named `bikes_main`. Split it into a training set `bikes_train` and a validation set `bikes_val`. Use `random_state=90`, a test set size of .2, and stratify on month. Remember to specify the data's index column as you read it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWIlhxR39wwq"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "bikes_main = pd.read_csv(\"data/bikes_student.csv\",index_col=\"Unnamed: 0\")\n",
    "bikes_train, bikes_val = train_test_split(bikes_main,test_size=0.2, random_state=90, stratify = bikes_main[\"month\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 36)\n",
      "(250, 36)\n"
     ]
    }
   ],
   "source": [
    "print(bikes_train.shape)\n",
    "print(bikes_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0YncxWuaW3k"
   },
   "source": [
    "**1.2** As with last homework, the response will be the `counts` column and we'll drop `counts`, `registered` and `casual` for being trivial predictors, drop `workingday` and `month` for being multicolinear with other columns, and `dteday` for being inappropriate for regression. Write code to do this.\n",
    "\n",
    "Encapsulate this process as a function with appropriate inputs and outputs, and test your code by producing `practice_y_train` and `practice_X_train`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "def x_y_split(df, target_column, columns_to_drop):\n",
    "    y = df[target_column]\n",
    "    df = df.drop(columns_to_drop + target_column, axis=1)\n",
    "    return df,y\n",
    "\n",
    "\n",
    "practice_X_train, practice_y_train = x_y_split(df=bikes_train,\\\n",
    "    target_column=[\"counts\"], columns_to_drop=[\"registered\",\"casual\",'workingday','dteday',\"month\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30)\n",
      "(1000, 1)\n",
      "Index(['hour', 'year', 'holiday', 'temp', 'atemp', 'hum', 'windspeed', 'Feb',\n",
      "       'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec',\n",
      "       'spring', 'summer', 'fall', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat',\n",
      "       'Cloudy', 'Snow', 'Storm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(practice_X_train.shape)\n",
    "print(practice_y_train.shape)\n",
    "print(practice_X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mr3zjw-Y48cx"
   },
   "source": [
    "**1.3** Write a function to standardize a provided subset of columns in your training/validation/test sets. Remember that while you will be scaling all of your data, you must learn the scaling parameters (mean and SD) from only the training set.\n",
    "\n",
    "Test your code by building a list of all non-binary columns in your `practice_X_train` and scaling only those columns. Call the result `practice_X_train_scaled`. Display the `.describe()` and verify that you have correctly scaled all columns, including the polynomial columns.\n",
    "\n",
    "**Hint: employ the provided list of binary columns and use `pd.columns.difference()`**\n",
    "\n",
    "`binary_columns = [ 'holiday','Feb', 'Mar', 'Apr',\n",
    "       'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec', 'spring',\n",
    "       'summer', 'fall', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat',\n",
    "       'Cloudy', 'Snow', 'Storm']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "pIm1TIqf48c4",
    "outputId": "af5391ee-8a4b-49da-ade4-4e8411fb412e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour         11.319000\n",
      "hum           0.639740\n",
      "atemp         0.472546\n",
      "temp          0.492780\n",
      "windspeed     0.195421\n",
      "dtype: float64\n",
      "hour         6.879431\n",
      "hum          0.188386\n",
      "atemp        0.171544\n",
      "temp         0.192935\n",
      "windspeed    0.125800\n",
      "dtype: float64\n",
      "       hour   hum   atemp  temp  windspeed\n",
      "15762    23  0.73  0.5152  0.54     0.1045\n",
      "4213     11  0.35  0.6667  0.76     0.2239\n",
      "14301     2  0.69  0.6212  0.66     0.0000\n",
      "15900     5  0.81  0.3030  0.30     0.1343\n",
      "14320    21  0.61  0.6515  0.70     0.1642\n",
      "               hour           hum         atemp          temp     windspeed\n",
      "count  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03\n",
      "mean  -9.588164e-17 -4.017564e-15  4.076295e-15 -4.009237e-15  8.886558e-15\n",
      "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00\n",
      "min   -1.645340e+00 -3.395903e+00 -2.401403e+00 -2.346801e+00 -1.553427e+00\n",
      "25%   -9.185353e-01 -7.417755e-01 -8.117208e-01 -7.918731e-01 -7.227439e-01\n",
      "50%   -4.637012e-02  5.446269e-02  7.143602e-02  3.742194e-02 -1.129730e-02\n",
      "75%    8.257951e-01  8.507009e-01  8.665686e-01  8.667170e-01  4.632654e-01\n",
      "max    1.697960e+00  1.912352e+00  2.544858e+00  2.317983e+00  5.208893e+00\n",
      "1    509\n",
      "0    491\n",
      "Name: year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "binary_columns = [ 'holiday','Feb', 'Mar', 'Apr',\n",
    "       'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec', 'spring',\n",
    "       'summer', 'fall', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat',\n",
    "       'Cloudy', 'Snow', 'Storm']\n",
    "\n",
    "binary_columns = binary_columns + [\"year\"]\n",
    "\n",
    "def scale_variable(df):\n",
    "    scale_columns = list(set(df.columns.values) - set(binary_columns))\n",
    "    mean = df[scale_columns].mean()\n",
    "    std = df[scale_columns].std()\n",
    "    print(mean)\n",
    "    print(std)\n",
    "    print(df[scale_columns].head())\n",
    "    return(df[scale_columns] - mean)/std\n",
    "\n",
    "practice_X_train_scaled = scale_variable(practice_X_train)\n",
    "\n",
    "print(practice_X_train_scaled.describe())\n",
    "print(practice_X_train.year.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since year is already a binary column, we do not need to scale in this case. We just need to add year as part of the binary column. The rest already normalized to be mean 0 and standard deviation 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEBl-5bU48ci"
   },
   "source": [
    "**1.4** Write a code to augment your a dataset with higher-order features for `temp`, `atemp`, `hum`,`windspeed`, and `hour`. You should include ONLY pure powers of these columns. So with degree=2 you should produce `atemp^2` and `hum^2` but not `atemp*hum` or any other two-feature interactions. \n",
    "\n",
    "\n",
    "Encapsulate this process as a function with apropriate inputs and outputs, and test your code by producing `practice_X_train_poly`, a training dataset with qudratic and cubic features built from `practice_X_train_scaled`, and printing `practice_X_train_poly`'s column names and `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "UXgj9yxu48cj",
    "outputId": "d1e9e4f7-41ab-4cae-a900-e11e0890638e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp^3' 'atemp^3' 'hum^3' 'windspeed^3' 'hour^3' 'temp^2' 'atemp^2'\n",
      " 'hum^2' 'windspeed^2' 'hour^2']\n",
      "         temp^3   atemp^3     hum^3  windspeed^3    hour^3    temp^2  \\\n",
      "15762  0.014660  0.015373  0.109987    -0.377532  4.895337  0.059900   \n",
      "4213   2.656894  1.449831 -3.638150     0.011602 -0.000100  1.918298   \n",
      "14301  0.651076  0.650742  0.018990    -3.748633 -2.485710  0.751198   \n",
      "15900 -0.997593 -0.965462  0.738233    -0.114692 -0.774975  0.998394   \n",
      "14320  1.238974  1.135279 -0.003934    -0.015286  2.786783  1.153564   \n",
      "\n",
      "        atemp^2     hum^2  windspeed^2    hour^2  \n",
      "15762  0.061827  0.229559     0.522359  2.883069  \n",
      "4213   1.280987  2.365486     0.051249  0.002150  \n",
      "14301  0.750941  0.071178     2.413137  1.834990  \n",
      "15900  0.976840  0.816825     0.236060  0.843707  \n",
      "14320  1.088266  0.024922     0.061594  1.980320  \n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "def higher_order(df, order, order_column):\n",
    "    new_df = pd.DataFrame(index=df.index)\n",
    "    while order > 1: \n",
    "        high_order = df[order_column]**order\n",
    "        col_names = [s + \"^\" + str(order) for s in order_column]\n",
    "        high_order.columns = col_names\n",
    "        new_df = new_df.merge(high_order,left_index=True, right_index=True)\n",
    "        order = order - 1\n",
    "    return new_df\n",
    "\n",
    "order_column = [\"temp\",\"atemp\",\"hum\",\"windspeed\",\"hour\"]\n",
    "    \n",
    "practice_X_train_poly = higher_order(df = practice_X_train_scaled, order = 3, order_column = order_column)\n",
    "\n",
    "                                                       \n",
    "print(practice_X_train_poly.columns.values)\n",
    "print(practice_X_train_poly.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pK5Mhlqc48dG"
   },
   "source": [
    "**1.5** Write code to add interaction terms to the model. Specifically, we want interactions between the continuous predictors (`temp`,`atemp`, `hum`,`windspeed`) and the month and weekday dummies (`Feb`, `Mar`...`Dec`, `Mon`, `Tue`, ... `Sat`). That means you SHOULD build `atemp*Feb` and `hum*Mon` and so on, but NOT `Feb*Mar` and NOT `Feb*Tue`. The interaction terms should always be a continuous feature times a month dummy or a continuous feature times a weekday dummy.\n",
    "\n",
    "\n",
    "Encapsulate this process as a function with appropriate inputs and outputs, and test your code by adding interaction terms to `practice_X_train_poly` and show its column names and `.head()`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gB6wlgj948dP",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def add_interaction(df, cont_predictor, dummy_predictor):\n",
    "    interaction = pd.DataFrame(index=df.index)\n",
    "    for continuous in cont_predictor:\n",
    "        for dummy in dummy_predictor:\n",
    "            new_predictor = pd.DataFrame(df[continuous]*df[dummy],columns=[continuous + \"*\" + dummy])\n",
    "            interaction = interaction.merge(new_predictor,left_index=True, right_index=True)\n",
    "    return interaction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp^3</th>\n",
       "      <th>atemp^3</th>\n",
       "      <th>hum^3</th>\n",
       "      <th>windspeed^3</th>\n",
       "      <th>hour^3</th>\n",
       "      <th>temp^2</th>\n",
       "      <th>atemp^2</th>\n",
       "      <th>hum^2</th>\n",
       "      <th>windspeed^2</th>\n",
       "      <th>hour^2</th>\n",
       "      <th>...</th>\n",
       "      <th>windspeed*Sept</th>\n",
       "      <th>windspeed*Oct</th>\n",
       "      <th>windspeed*Nov</th>\n",
       "      <th>windspeed*Dec</th>\n",
       "      <th>windspeed*Mon</th>\n",
       "      <th>windspeed*Tue</th>\n",
       "      <th>windspeed*Wed</th>\n",
       "      <th>windspeed*Thu</th>\n",
       "      <th>windspeed*Fri</th>\n",
       "      <th>windspeed*Sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15762</th>\n",
       "      <td>0.014660</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>0.109987</td>\n",
       "      <td>-0.377532</td>\n",
       "      <td>4.895337</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.061827</td>\n",
       "      <td>0.229559</td>\n",
       "      <td>0.522359</td>\n",
       "      <td>2.883069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.722744</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.722744</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>2.656894</td>\n",
       "      <td>1.449831</td>\n",
       "      <td>-3.638150</td>\n",
       "      <td>0.011602</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>1.918298</td>\n",
       "      <td>1.280987</td>\n",
       "      <td>2.365486</td>\n",
       "      <td>0.051249</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14301</th>\n",
       "      <td>0.651076</td>\n",
       "      <td>0.650742</td>\n",
       "      <td>0.018990</td>\n",
       "      <td>-3.748633</td>\n",
       "      <td>-2.485710</td>\n",
       "      <td>0.751198</td>\n",
       "      <td>0.750941</td>\n",
       "      <td>0.071178</td>\n",
       "      <td>2.413137</td>\n",
       "      <td>1.834990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.553427</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15900</th>\n",
       "      <td>-0.997593</td>\n",
       "      <td>-0.965462</td>\n",
       "      <td>0.738233</td>\n",
       "      <td>-0.114692</td>\n",
       "      <td>-0.774975</td>\n",
       "      <td>0.998394</td>\n",
       "      <td>0.976840</td>\n",
       "      <td>0.816825</td>\n",
       "      <td>0.236060</td>\n",
       "      <td>0.843707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.485860</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.485860</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14320</th>\n",
       "      <td>1.238974</td>\n",
       "      <td>1.135279</td>\n",
       "      <td>-0.003934</td>\n",
       "      <td>-0.015286</td>\n",
       "      <td>2.786783</td>\n",
       "      <td>1.153564</td>\n",
       "      <td>1.088266</td>\n",
       "      <td>0.024922</td>\n",
       "      <td>0.061594</td>\n",
       "      <td>1.980320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.248181</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         temp^3   atemp^3     hum^3  windspeed^3    hour^3    temp^2  \\\n",
       "15762  0.014660  0.015373  0.109987    -0.377532  4.895337  0.059900   \n",
       "4213   2.656894  1.449831 -3.638150     0.011602 -0.000100  1.918298   \n",
       "14301  0.651076  0.650742  0.018990    -3.748633 -2.485710  0.751198   \n",
       "15900 -0.997593 -0.965462  0.738233    -0.114692 -0.774975  0.998394   \n",
       "14320  1.238974  1.135279 -0.003934    -0.015286  2.786783  1.153564   \n",
       "\n",
       "        atemp^2     hum^2  windspeed^2    hour^2      ...        \\\n",
       "15762  0.061827  0.229559     0.522359  2.883069      ...         \n",
       "4213   1.280987  2.365486     0.051249  0.002150      ...         \n",
       "14301  0.750941  0.071178     2.413137  1.834990      ...         \n",
       "15900  0.976840  0.816825     0.236060  0.843707      ...         \n",
       "14320  1.088266  0.024922     0.061594  1.980320      ...         \n",
       "\n",
       "       windspeed*Sept  windspeed*Oct  windspeed*Nov  windspeed*Dec  \\\n",
       "15762            -0.0      -0.722744           -0.0           -0.0   \n",
       "4213              0.0       0.000000            0.0            0.0   \n",
       "14301            -0.0      -0.000000           -0.0           -0.0   \n",
       "15900            -0.0      -0.485860           -0.0           -0.0   \n",
       "14320            -0.0      -0.000000           -0.0           -0.0   \n",
       "\n",
       "       windspeed*Mon  windspeed*Tue  windspeed*Wed  windspeed*Thu  \\\n",
       "15762           -0.0      -0.722744      -0.000000           -0.0   \n",
       "4213             0.0       0.000000       0.226382            0.0   \n",
       "14301           -0.0      -0.000000      -0.000000           -0.0   \n",
       "15900           -0.0      -0.000000      -0.485860           -0.0   \n",
       "14320           -0.0      -0.000000      -0.000000           -0.0   \n",
       "\n",
       "       windspeed*Fri  windspeed*Sat  \n",
       "15762      -0.000000           -0.0  \n",
       "4213        0.000000            0.0  \n",
       "14301      -1.553427           -0.0  \n",
       "15900      -0.000000           -0.0  \n",
       "14320      -0.248181           -0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_columns = list(set(practice_X_train.columns.values) - set(binary_columns))\n",
    "cont_predictor = [\"temp\",\"atemp\",\"hum\",\"windspeed\"]\n",
    "dummy_predictor = [ 'Feb', 'Mar', 'Apr',\n",
    "       'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec',\n",
    "        'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\n",
    "\n",
    "\n",
    "df = practice_X_train[binary_columns].merge(practice_X_train_scaled,left_index=True, right_index = True)\n",
    "\n",
    "practice_X_train_poly = practice_X_train_poly.merge(\\\n",
    "    add_interaction(df, cont_predictor, dummy_predictor),left_index=True,right_index=True)\n",
    "\n",
    "practice_X_train_poly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGd5qdPu48da"
   },
   "source": [
    "**1.6** Combine all your code so far into a function that takes in `bikes_train`, `bikes_val`, the names of columns for polynomial, the target column, the columns to be dropped and produces computation-ready design matrices `X_train` and `X_val` and responses `y_train` and `y_val`. Your final function should build correct, scaled design matrices with the stated interaction terms and any polynomial degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_design_mats(train_df, val_df,  degree, \n",
    "                    columns_forpoly=['temp', 'atemp', 'hum','windspeed', 'hour'],\n",
    "                    target_col='counts', \n",
    "                    bad_columns=['counts', 'registered', 'casual', 'workingday', 'month', 'dteday']):\n",
    "    # add code here \n",
    "    \n",
    "    practice_X_train, y_train = x_y_split(df=train_df,\\\n",
    "    target_column=[target_col], columns_to_drop=bad_columns)\n",
    "    \n",
    "    practice_X_val, y_val = x_y_split(df=val_df,\\\n",
    "    target_column=[target_col], columns_to_drop=bad_columns)\n",
    "    \n",
    "    practice_X_train_scaled = scale_variable(practice_X_train)\n",
    "    practice_X_val_scaled = scale_variable(practice_X_val)\n",
    "\n",
    "    practice_X_train_poly = higher_order(df = practice_X_train_scaled, order = degree,order_column = columns_forpoly)\n",
    "    practice_X_val_poly = higher_order(df = practice_X_val_scaled, order = degree,order_column = columns_forpoly)\n",
    "\n",
    "                                                       \n",
    "    scale_columns = list(set(practice_X_train.columns.values) - set(binary_columns))\n",
    "    continuous_columns = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "    dummy_predictor = [ 'Feb', 'Mar', 'Apr',\n",
    "           'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec',\n",
    "            'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\n",
    "\n",
    "\n",
    "    x_train = practice_X_train[binary_columns].merge(practice_X_train_scaled,left_index=True, right_index = True)\n",
    "    x_val = practice_X_val[binary_columns].merge(practice_X_val_scaled,left_index=True, right_index = True)\n",
    "\n",
    "    df_train = practice_X_train[binary_columns].merge(practice_X_train_scaled,left_index=True, right_index = True)\n",
    "\n",
    "    df_val = practice_X_val[binary_columns].merge(practice_X_val_scaled,left_index=True, right_index = True)\n",
    "\n",
    "    \n",
    "    practice_X_train_poly = practice_X_train_poly.merge(\\\n",
    "        add_interaction(df_train, continuous_columns, dummy_predictor),left_index=True,right_index=True)\n",
    "    practice_X_val_poly = practice_X_val_poly.merge(\\\n",
    "        add_interaction(df_val, continuous_columns, dummy_predictor),left_index=True,right_index=True)\n",
    "    \n",
    "    x_train = x_train.merge(practice_X_train_poly,left_index=True,right_index=True)\n",
    "    x_val = x_val.merge(practice_X_val_poly,left_index=True,right_index=True)\n",
    "\n",
    "    \n",
    "    return x_train,y_train, x_val,y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour         11.319000\n",
      "hum           0.639740\n",
      "atemp         0.472546\n",
      "temp          0.492780\n",
      "windspeed     0.195421\n",
      "dtype: float64\n",
      "hour         6.879431\n",
      "hum          0.188386\n",
      "atemp        0.171544\n",
      "temp         0.192935\n",
      "windspeed    0.125800\n",
      "dtype: float64\n",
      "       hour   hum   atemp  temp  windspeed\n",
      "15762    23  0.73  0.5152  0.54     0.1045\n",
      "4213     11  0.35  0.6667  0.76     0.2239\n",
      "14301     2  0.69  0.6212  0.66     0.0000\n",
      "15900     5  0.81  0.3030  0.30     0.1343\n",
      "14320    21  0.61  0.6515  0.70     0.1642\n",
      "hour         11.776000\n",
      "hum           0.633240\n",
      "atemp         0.477820\n",
      "temp          0.499680\n",
      "windspeed     0.204845\n",
      "dtype: float64\n",
      "hour         6.911214\n",
      "hum          0.187639\n",
      "atemp        0.172640\n",
      "temp         0.191179\n",
      "windspeed    0.116051\n",
      "dtype: float64\n",
      "       hour   hum   atemp  temp  windspeed\n",
      "8512     10  0.42  0.2879  0.34     0.5224\n",
      "14196    17  0.78  0.5909  0.64     0.1045\n",
      "8716      0  0.42  0.0606  0.08     0.3284\n",
      "7913      9  0.52  0.2727  0.30     0.3284\n",
      "7403      2  0.94  0.3939  0.38     0.0000\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "x_train,y_train, x_val,y_val = get_design_mats(bikes_train, bikes_val,  degree=3, \n",
    "                    columns_forpoly=['temp', 'atemp', 'hum','windspeed', 'hour'],\n",
    "                    target_col='counts', \n",
    "                    bad_columns=['counts', 'registered', 'casual', 'workingday', 'month', 'dteday'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sept</th>\n",
       "      <th>Oct</th>\n",
       "      <th>...</th>\n",
       "      <th>windspeed*Sept</th>\n",
       "      <th>windspeed*Oct</th>\n",
       "      <th>windspeed*Nov</th>\n",
       "      <th>windspeed*Dec</th>\n",
       "      <th>windspeed*Mon</th>\n",
       "      <th>windspeed*Tue</th>\n",
       "      <th>windspeed*Wed</th>\n",
       "      <th>windspeed*Thu</th>\n",
       "      <th>windspeed*Fri</th>\n",
       "      <th>windspeed*Sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.08300</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.08300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014074</td>\n",
       "      <td>-0.014795</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>-0.017200</td>\n",
       "      <td>-0.013914</td>\n",
       "      <td>-0.013259</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>-0.011262</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.017327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.162164</td>\n",
       "      <td>0.268306</td>\n",
       "      <td>0.279021</td>\n",
       "      <td>0.274502</td>\n",
       "      <td>0.280504</td>\n",
       "      <td>0.27602</td>\n",
       "      <td>0.280504</td>\n",
       "      <td>0.279021</td>\n",
       "      <td>0.274502</td>\n",
       "      <td>0.27602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242807</td>\n",
       "      <td>0.280949</td>\n",
       "      <td>0.288629</td>\n",
       "      <td>0.310342</td>\n",
       "      <td>0.370245</td>\n",
       "      <td>0.345850</td>\n",
       "      <td>0.403001</td>\n",
       "      <td>0.311904</td>\n",
       "      <td>0.376244</td>\n",
       "      <td>0.428051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.553427</td>\n",
       "      <td>-1.553427</td>\n",
       "      <td>-1.553427</td>\n",
       "      <td>-1.553427</td>\n",
       "      <td>-1.553427</td>\n",
       "      <td>-1.553427</td>\n",
       "      <td>-1.553427</td>\n",
       "      <td>-1.553427</td>\n",
       "      <td>-1.553427</td>\n",
       "      <td>-1.553427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.599195</td>\n",
       "      <td>2.599195</td>\n",
       "      <td>2.836079</td>\n",
       "      <td>3.310642</td>\n",
       "      <td>4.141325</td>\n",
       "      <td>2.599195</td>\n",
       "      <td>2.599195</td>\n",
       "      <td>3.666763</td>\n",
       "      <td>3.310642</td>\n",
       "      <td>3.666763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           holiday          Feb          Mar          Apr          May  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.027000     0.078000     0.085000     0.082000     0.086000   \n",
       "std       0.162164     0.268306     0.279021     0.274502     0.280504   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              Jun          Jul          Aug         Sept         Oct  \\\n",
       "count  1000.00000  1000.000000  1000.000000  1000.000000  1000.00000   \n",
       "mean      0.08300     0.086000     0.085000     0.082000     0.08300   \n",
       "std       0.27602     0.280504     0.279021     0.274502     0.27602   \n",
       "min       0.00000     0.000000     0.000000     0.000000     0.00000   \n",
       "25%       0.00000     0.000000     0.000000     0.000000     0.00000   \n",
       "50%       0.00000     0.000000     0.000000     0.000000     0.00000   \n",
       "75%       0.00000     0.000000     0.000000     0.000000     0.00000   \n",
       "max       1.00000     1.000000     1.000000     1.000000     1.00000   \n",
       "\n",
       "           ...        windspeed*Sept  windspeed*Oct  windspeed*Nov  \\\n",
       "count      ...           1000.000000    1000.000000    1000.000000   \n",
       "mean       ...             -0.014074      -0.014795       0.001708   \n",
       "std        ...              0.242807       0.280949       0.288629   \n",
       "min        ...             -1.553427      -1.553427      -1.553427   \n",
       "25%        ...              0.000000       0.000000       0.000000   \n",
       "50%        ...             -0.000000       0.000000      -0.000000   \n",
       "75%        ...              0.000000       0.000000       0.000000   \n",
       "max        ...              2.599195       2.599195       2.836079   \n",
       "\n",
       "       windspeed*Dec  windspeed*Mon  windspeed*Tue  windspeed*Wed  \\\n",
       "count    1000.000000    1000.000000    1000.000000    1000.000000   \n",
       "mean       -0.017200      -0.013914      -0.013259       0.004384   \n",
       "std         0.310342       0.370245       0.345850       0.403001   \n",
       "min        -1.553427      -1.553427      -1.553427      -1.553427   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%        -0.000000       0.000000      -0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         3.310642       4.141325       2.599195       2.599195   \n",
       "\n",
       "       windspeed*Thu  windspeed*Fri  windspeed*Sat  \n",
       "count    1000.000000    1000.000000    1000.000000  \n",
       "mean       -0.011262       0.001800       0.017327  \n",
       "std         0.311904       0.376244       0.428051  \n",
       "min        -1.553427      -1.553427      -1.553427  \n",
       "25%         0.000000       0.000000      -0.000000  \n",
       "50%         0.000000      -0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000  \n",
       "max         3.666763       3.310642       3.666763  \n",
       "\n",
       "[8 rows x 108 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>194.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>191.635042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>136.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>287.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>970.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            counts\n",
       "count  1000.000000\n",
       "mean    194.279000\n",
       "std     191.635042\n",
       "min       1.000000\n",
       "25%      35.000000\n",
       "50%     136.500000\n",
       "75%     287.250000\n",
       "max     970.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_train.describe())\n",
    "display(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['holiday',\n",
       " 'Feb',\n",
       " 'Mar',\n",
       " 'Apr',\n",
       " 'May',\n",
       " 'Jun',\n",
       " 'Jul',\n",
       " 'Aug',\n",
       " 'Sept',\n",
       " 'Oct',\n",
       " 'Nov',\n",
       " 'Dec',\n",
       " 'spring',\n",
       " 'summer',\n",
       " 'fall',\n",
       " 'Mon',\n",
       " 'Tue',\n",
       " 'Wed',\n",
       " 'Thu',\n",
       " 'Fri',\n",
       " 'Sat',\n",
       " 'Cloudy',\n",
       " 'Snow',\n",
       " 'Storm',\n",
       " 'year',\n",
       " 'hour',\n",
       " 'hum',\n",
       " 'atemp',\n",
       " 'temp',\n",
       " 'windspeed',\n",
       " 'temp^3',\n",
       " 'atemp^3',\n",
       " 'hum^3',\n",
       " 'windspeed^3',\n",
       " 'hour^3',\n",
       " 'temp^2',\n",
       " 'atemp^2',\n",
       " 'hum^2',\n",
       " 'windspeed^2',\n",
       " 'hour^2',\n",
       " 'temp*Feb',\n",
       " 'temp*Mar',\n",
       " 'temp*Apr',\n",
       " 'temp*May',\n",
       " 'temp*Jun',\n",
       " 'temp*Jul',\n",
       " 'temp*Aug',\n",
       " 'temp*Sept',\n",
       " 'temp*Oct',\n",
       " 'temp*Nov',\n",
       " 'temp*Dec',\n",
       " 'temp*Mon',\n",
       " 'temp*Tue',\n",
       " 'temp*Wed',\n",
       " 'temp*Thu',\n",
       " 'temp*Fri',\n",
       " 'temp*Sat',\n",
       " 'atemp*Feb',\n",
       " 'atemp*Mar',\n",
       " 'atemp*Apr',\n",
       " 'atemp*May',\n",
       " 'atemp*Jun',\n",
       " 'atemp*Jul',\n",
       " 'atemp*Aug',\n",
       " 'atemp*Sept',\n",
       " 'atemp*Oct',\n",
       " 'atemp*Nov',\n",
       " 'atemp*Dec',\n",
       " 'atemp*Mon',\n",
       " 'atemp*Tue',\n",
       " 'atemp*Wed',\n",
       " 'atemp*Thu',\n",
       " 'atemp*Fri',\n",
       " 'atemp*Sat',\n",
       " 'hum*Feb',\n",
       " 'hum*Mar',\n",
       " 'hum*Apr',\n",
       " 'hum*May',\n",
       " 'hum*Jun',\n",
       " 'hum*Jul',\n",
       " 'hum*Aug',\n",
       " 'hum*Sept',\n",
       " 'hum*Oct',\n",
       " 'hum*Nov',\n",
       " 'hum*Dec',\n",
       " 'hum*Mon',\n",
       " 'hum*Tue',\n",
       " 'hum*Wed',\n",
       " 'hum*Thu',\n",
       " 'hum*Fri',\n",
       " 'hum*Sat',\n",
       " 'windspeed*Feb',\n",
       " 'windspeed*Mar',\n",
       " 'windspeed*Apr',\n",
       " 'windspeed*May',\n",
       " 'windspeed*Jun',\n",
       " 'windspeed*Jul',\n",
       " 'windspeed*Aug',\n",
       " 'windspeed*Sept',\n",
       " 'windspeed*Oct',\n",
       " 'windspeed*Nov',\n",
       " 'windspeed*Dec',\n",
       " 'windspeed*Mon',\n",
       " 'windspeed*Tue',\n",
       " 'windspeed*Wed',\n",
       " 'windspeed*Thu',\n",
       " 'windspeed*Fri',\n",
       " 'windspeed*Sat',\n",
       " 'hour*Feb',\n",
       " 'hour*Mar',\n",
       " 'hour*Apr',\n",
       " 'hour*May',\n",
       " 'hour*Jun',\n",
       " 'hour*Jul',\n",
       " 'hour*Aug',\n",
       " 'hour*Sept',\n",
       " 'hour*Oct',\n",
       " 'hour*Nov',\n",
       " 'hour*Dec',\n",
       " 'hour*Mon',\n",
       " 'hour*Tue',\n",
       " 'hour*Wed',\n",
       " 'hour*Thu',\n",
       " 'hour*Fri',\n",
       " 'hour*Sat']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 2 [20pts]: Regularization via Ridge </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** For each degree in 1 through 8:\n",
    "\n",
    "1.  Build the training design matrix and validation design matrix using the function `get_design_mats` with polynomial terms up through the specified degree.\n",
    "\n",
    "2.  Fit a regression model to the training data.\n",
    "\n",
    "3.  Report the model's score on the validation data.\n",
    "\n",
    "**2.2** Discuss patterns you see in the results from 2.1. Which model would you select, and why?\n",
    "\n",
    "**2.3** Let's try regularizing our models via ridge regression. Build a table showing the validation set $R^2$ of polynomial models with degree from 1-8, regularized at the levels $\\lambda = (.01, .05, .1,.5, 1, 5, 10, 50, 100)$. Do not perform cross validation at this point, simply report performance on the single validation set. \n",
    "\n",
    "**2.4** Find the best-scoring degree and regularization combination.\n",
    "\n",
    "**2.5** It's time to see how well our selected model will do on future data. Read in the provided test dataset, do any required formatting, and report the best model's $R^2$ score. How does it compare to the validation set score that made us choose this model? \n",
    "\n",
    "**2.6** Why do you think our model's test score was quite a bit worse than its validation score? Does the test set simply contain harder examples, or is something else going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** For each degree in 1 through 8:\n",
    "\n",
    "1.  Build the training design matrix and validation design matrix using the function `get_design_mats` with polynomial terms up through the specified degree.\n",
    "\n",
    "2.  Fit a regression model to the training data.\n",
    "\n",
    "3.  Report the model's score on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "id": "VTWx4demHUo0",
    "outputId": "fb9ca7f7-8b7b-42e5-fab8-471ab5f57180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree=1 R2 is 0.3070625284801659\n",
      "degree=2 R2 is 0.4317070296364137\n",
      "degree=3 R2 is 0.440953168759604\n",
      "degree=4 R2 is 0.42497025057567084\n",
      "degree=5 R2 is 0.4500905533203593\n",
      "degree=6 R2 is 0.4399045279834466\n",
      "degree=7 R2 is 0.5151931525046574\n",
      "degree=8 R2 is 0.5268281034236888\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "for i in range(8):\n",
    "    degree = i + 1\n",
    "    x_train,y_train, x_val,y_val = get_design_mats(bikes_train, bikes_val,  degree=degree, \n",
    "                    columns_forpoly=['temp', 'atemp', 'hum','windspeed', 'hour'],\n",
    "                    target_col='counts', \n",
    "                    bad_columns=['counts', 'registered', 'casual', 'workingday', 'month', 'dteday'])\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    model.fit(x_train, y_train)\n",
    "    print(\"degree=\" + str(degree) + \" R2 is \"+ str(model.score(x_val, y_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** Discuss patterns you see in the results from 2.1. Which model would you select, and why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQJ1vesGNwOf"
   },
   "source": [
    "**2.3** Let's try regularizing our models via ridge regression. Build a table showing the validation set $R^2$ of polynomial models with degree from 1-8, regularized at the levels $\\lambda = (.01, .05, .1,.5, 1, 5, 10, 50, 100)$. Do not perform cross validation at this point, simply report performance on the single validation set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "GUvYAWHzQAmb",
    "outputId": "7a60ee39-ee8e-46a9-aff7-781580b83717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        degree = 1  degree = 2  degree = 3  degree = 4  degree = 5  \\\n",
      "lambda                                                               \n",
      "0.01      0.300993    0.429663    0.441791    0.425953    0.450822   \n",
      "0.05      0.303176    0.432009    0.444625    0.428492    0.452848   \n",
      "0.10      0.305184    0.433979    0.447146    0.430692    0.454600   \n",
      "0.50      0.312647    0.440776    0.455151    0.438267    0.460434   \n",
      "1.00      0.316718    0.444049    0.458541    0.441977    0.463182   \n",
      "5.00      0.327070    0.449509    0.465555    0.451313    0.470205   \n",
      "10.00     0.331584    0.450134    0.468372    0.455468    0.473775   \n",
      "50.00     0.339529    0.447242    0.468994    0.458672    0.480282   \n",
      "100.00    0.338378    0.443471    0.460486    0.452240    0.479344   \n",
      "\n",
      "        degree = 6  degree = 7  degree = 8  \n",
      "lambda                                      \n",
      "0.01      0.440778    0.515793    0.527969  \n",
      "0.05      0.442612    0.516722    0.530418  \n",
      "0.10      0.444217    0.517168    0.531787  \n",
      "0.50      0.451518    0.515893    0.528637  \n",
      "1.00      0.456493    0.512248    0.520153  \n",
      "5.00      0.469728    0.495575    0.491498  \n",
      "10.00     0.475153    0.490066    0.483984  \n",
      "50.00     0.487068    0.484676    0.477598  \n",
      "100.00    0.487945    0.481966    0.477337  \n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "alphas = [0.01,0.05,0.1,0.5,1,5,10,50,100]\n",
    "R2_table = pd.DataFrame(alphas,columns=[\"lambda\"])\n",
    "for i in range(8):\n",
    "    order = i + 1\n",
    "    x_train,y_train, x_val,y_val = get_design_mats(bikes_train, bikes_val,  degree=order, \n",
    "                    columns_forpoly=['temp', 'atemp', 'hum','windspeed', 'hour'],\n",
    "                    target_col='counts', \n",
    "                    bad_columns=['counts', 'registered', 'casual', 'workingday', 'month', 'dteday'])\n",
    "    \n",
    "    degree = []\n",
    "    for a in alphas:\n",
    "        clf = Ridge(alpha=a)\n",
    "        clf.fit(x_train, y_train)\n",
    "        degree = degree + [clf.score(x_val,y_val)]\n",
    "        \n",
    "    \n",
    "    R2_table[\"degree = \" + str(order)] = degree\n",
    "    \n",
    "R2_table = R2_table.set_index(\"lambda\")\n",
    "\n",
    "print(R2_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBwFV1wCTWnw"
   },
   "source": [
    "**2.4** Find the best-scoring degree and regularization combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "1zminoljTm9y",
    "outputId": "b12035c4-5a20-4449-fed4-dcc5e81c0db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best-scoring degree is degree = 8\n",
      "the best-scoring lambda is 0.1\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print(\"the best-scoring degree is \" + R2_table.max().idxmax())\n",
    "print(\"the best-scoring lambda is \" + str(R2_table[R2_table.max().idxmax()].idxmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KU3rqk4qU5BK"
   },
   "source": [
    "**2.5** It's time to see how well our selected model will do on future data. Read in the provided test dataset `data/bikes_test.csv`, do any required formatting, and report the best model's $R^2$ score. How does it compare to the validation set score that made us choose this model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cbzfV7HaW_U1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5839960855857602"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "val_df = bikes_test\n",
    "bikes_test = pd.read_csv(\"data/bikes_test.csv\",index_col=\"Unnamed: 0\")\n",
    "\n",
    "\n",
    "\n",
    "x_train,y_train, x_test, y_test = get_design_mats(train_df = bikes_train, val_df = bikes_test,  degree=8, \n",
    "                    columns_forpoly=['temp', 'atemp', 'hum','windspeed', 'hour'],\n",
    "                    target_col='counts', \n",
    "                    bad_columns=['counts', 'registered', 'casual', 'workingday', 'month', 'dteday'])\n",
    "\n",
    "\n",
    "clf = Ridge(alpha=0.1)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test,y_test)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6** Why do you think our model's test score was quite a bit worse than its validation score? Does the test set simply contain harder examples, or is something else going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Question 3 [20pts]: Comparing Ridge, Lasso, and OLS </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Build a dataset with polynomial degree 1 and fit an OLS model, a Ridge model, and a Lasso model. Use `RidgeCV` and `LassoCV` to select the best regularization level from among `(.1,.5,1,5,10,50,100)`. \n",
    "\n",
    "Note: On the lasso model, you will need to increase `max_iter` to 100,000 for the optimization to converge.\n",
    "\n",
    "**3.2** Plot histograms of the coefficients found by each of OLS, ridge, and lasso. What trends do you see in the magnitude of the coefficients?\n",
    "\n",
    "**3.3** The plots above show the overall distribution of coefficient values in each model, but do not show how each model treats individual coefficients. Build a plot which cleanly presents, for each feature in the data, 1) The coefficient assigned by OLS, 2) the coefficient assigned by ridge, and 3) the coefficient assigned by lasso.\n",
    "\n",
    "**Hint: Bar plots are a possible choice, but you are not required to use them**\n",
    "\n",
    "**Hint: use `xticks` to label coefficients with their feature names**\n",
    "\n",
    "**3.4** What trends do you see in the plot above? How do the three approaches handle the correlated pair `temp` and `atemp`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Build a dataset with polynomial degree 1 and fit an OLS model, a Ridge model, and a Lasso model. Use `RidgeCV` and `LassoCV` to select the best regularization level from among `(.1,.5,1,5,10,50,100)`. \n",
    "\n",
    "Note: On the lasso model, you will need to increase `max_iter` to 100,000 for the optimization to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**3.2** Plot histograms of the coefficients found by each of OLS, ridge, and lasso. What trends do you see in the magnitude of the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3** The plots above show the overall distribution of coefficient values in each model, but do not show how each model treats individual coefficients. Build a plot which cleanly presents, for each feature in the data, 1) The coefficient assigned by OLS, 2) the coefficient assigned by ridge, and 3) the coefficient assigned by lasso.\n",
    "\n",
    "**Hint: Bar plots are a possible choice, but you are not required to use them**\n",
    "\n",
    "**Hint: use `xticks` to label coefficients with their feature names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4** What trends do you see in the plot above? How do the three approaches handle the correlated pair `temp` and `atemp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 4 [20 pts]: Reflection </b></div>\n",
    "These problems are open-ended, and you are not expected to write more than 2-3 sentences. We are interested in seeing that you have thought about these issues; you will be graded on how well you justify your conclusions here, not on what you conclude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1** Reflect back on the `get_design_mats` function you built. Writing this function useful in your analysis? What issues might you have encountered if you copy/pasted the model-building code instead of tying it together in a function? Does a `get_design_mat` function seem wise in general, or are there better options?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2** What are the costs and benefits of applying ridge/lasso regularization to an overfit OLS model, versus setting a specific degree of polynomial or forward selecting features for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.3** This pset posed a purely predictive goal: forecast ridership as accurately as possible. How important is interpretability in this context? Considering, e.g., your lasso and ridge models from Question 3, how would you react if the models predicted well, but the coefficient values didn't make sense once interpreted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**4.4** Reflect back on our original goal of helping BikeShare predict what demand will be like in the week ahead, and thus how many bikes they can bring in for maintenance. In your view, did we accomplish this goal? If yes, which model would you put into production and why? If not, which model came closest, what other analyses might you conduct, and how likely do you think they are to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "day_level_test.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
